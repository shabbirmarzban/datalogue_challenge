{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import io\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response_text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Friends often come to me to talk about the iss...</td>\n",
       "      <td>not_flagged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            response_text        class\n",
       "count                                                  80           80\n",
       "unique                                                 80            2\n",
       "top     Friends often come to me to talk about the iss...  not_flagged\n",
       "freq                                                    1           55"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./Sheet_1.csv\",usecols=['response_id','class','response_text'],encoding='latin-1')\n",
    "data = shuffle(data, random_state=12345)\n",
    "labels = np.asarray(data['class']== 'flagged',dtype=int)\n",
    "data = data[['response_text','class']]\n",
    "data.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#wpt = nltk.WordPunctTokenizer()\n",
    "wpt = nltk.RegexpTokenizer(r'\\w+')\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-z,A-Z\\s]', '', doc, re.I)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    # tokenize document\n",
    "    tokens = wpt.tokenize(doc)\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "normalize_corpus = np.vectorize(normalize_document)\n",
    "normed_data = normalize_corpus(data['response_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and retrieve Vectors\n",
    "To generate word level features, pretrained word2vec model from Fasttext is used. This model is trained CommonCrawl corpus and has 2M word_vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = map(float, tokens[1:])\n",
    "    return data\n",
    "\n",
    "word_vectors = load_vectors('./word_2_vec_model/crawl-300d-2M.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 0\n",
      "Done with 10\n",
      "Done with 20\n",
      "Word virgity not in vocab\n",
      "Done with 30\n",
      "Word theripist not in vocab\n",
      "Done with 40\n",
      "Done with 50\n",
      "Word cuttersuicidal not in vocab\n",
      "Done with 60\n",
      "Word irlsomeone not in vocab\n",
      "Word campingsurfing not in vocab\n",
      "Done with 70\n",
      "Word geds not in vocab\n"
     ]
    }
   ],
   "source": [
    "# retrieve vectors for all tokens.\n",
    "data_vectors = []\n",
    "for i, sentence in enumerate(normed_data):\n",
    "    words = sentence.split(' ')\n",
    "    vectors=[]\n",
    "    for w in words:\n",
    "        if w in word_vectors.keys():\n",
    "            vectors.append(word_vectors[w])\n",
    "        else:\n",
    "            print(\"Word {} not in vocab\".format(w))\n",
    "    data_vectors.append(vectors)\n",
    "    if i % 10 ==0:\n",
    "        print 'Done with %d' % i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Features\n",
    "Here sentence(sample) level features are generated by taking mean of token-words in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "for vv in data_vectors:\n",
    "    features.append(np.mean(vv,axis=0 ))\n",
    "features= np.asarray(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Util for Confusion Matrix - Taken from sklearn doc.\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "For training, 5-fold crossvalidation is employed since we have very less data to play with. These folds are startified since there is significant imbalance between not_flagged(0) and flagged(1) classes. In each of the fold, grid search is performend on train/val set to find best hyper parameters(C). ATM only SVM is used as classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 Report\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      0.73      1.00      0.84      0.85      0.71        11\n",
      "          1       0.62      1.00      0.73      0.77      0.85      0.75         5\n",
      "\n",
      "avg / total       0.88      0.81      0.91      0.82      0.85      0.72        16\n",
      "\n",
      "Best Classfier\n",
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      ".....\n",
      "Fold 1 Report\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.92      1.00      0.80      0.96      0.89      0.82        11\n",
      "          1       1.00      0.80      1.00      0.89      0.89      0.78         5\n",
      "\n",
      "avg / total       0.94      0.94      0.86      0.94      0.89      0.81        16\n",
      "\n",
      "Best Classfier\n",
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      ".....\n",
      "Fold 2 Report\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.77      0.91      0.40      0.83      0.60      0.38        11\n",
      "          1       0.67      0.40      0.91      0.50      0.60      0.35         5\n",
      "\n",
      "avg / total       0.74      0.75      0.56      0.73      0.60      0.37        16\n",
      "\n",
      "Best Classfier\n",
      "SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      ".....\n",
      "Fold 3 Report\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.83      0.91      0.60      0.87      0.74      0.56        11\n",
      "          1       0.75      0.60      0.91      0.67      0.74      0.53         5\n",
      "\n",
      "avg / total       0.81      0.81      0.70      0.81      0.74      0.55        16\n",
      "\n",
      "Best Classfier\n",
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      ".....\n",
      "Fold 4 Report\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.90      0.82      0.80      0.86      0.81      0.66        11\n",
      "          1       0.67      0.80      0.82      0.73      0.81      0.65         5\n",
      "\n",
      "avg / total       0.83      0.81      0.81      0.82      0.81      0.65        16\n",
      "\n",
      "Best Classfier\n",
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      ".....\n",
      "Combining test prediction of all folds:\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.87      0.87      0.72      0.87      0.79      0.64        55\n",
      "          1       0.72      0.72      0.87      0.72      0.79      0.62        25\n",
      "\n",
      "avg / total       0.82      0.82      0.77      0.82      0.79      0.63        80\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "[[48  7]\n",
      " [ 7 18]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=1234, shuffle=False)\n",
    "y_test_all, y_pred_all = [],[]\n",
    "\n",
    "for i, [train_index, test_index] in enumerate(skf.split(features,labels)):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "    # Over sample to balance the classes.\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_res, y_res = ros.fit_sample(X_train, y_train)\n",
    "    \n",
    "    # Grid search\n",
    "    h_parameters = {'C':[0.01, 0.1, 1, 10, 100, 1000]}\n",
    "    svc = svm.SVC(kernel='rbf')\n",
    "    clf = GridSearchCV(svc, h_parameters)\n",
    "    clf.fit(X_res, y_res)\n",
    "\n",
    "    #prediction on test-fold\n",
    "    y_pred = clf.best_estimator_.predict(X_test)\n",
    "    y_test_all.extend(y_test)\n",
    "    y_pred_all.extend(y_pred)\n",
    "    print 'Fold %d Report' % i\n",
    "    print(classification_report_imbalanced(y_test, y_pred))\n",
    "    print 'Best Classfier'\n",
    "    print clf.best_estimator_\n",
    "    print '.....'\n",
    "\n",
    "print 'Combining test prediction of all folds:'\n",
    "print(classification_report_imbalanced(y_test_all, y_pred_all))\n",
    "plt.figure()\n",
    "cnf_matrix = confusion_matrix(y_test_all, y_pred_all)\n",
    "plot_confusion_matrix(cnf_matrix, classes=['nf','f'],\n",
    "                  title='CM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.825\n"
     ]
    }
   ],
   "source": [
    "print 'Accuracy:', np.sum(np.asarray(y_test_all)==np.asarray(y_pred_all))/float(len(y_pred_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Step:\n",
    " - weight the word_vectors using tfidf scores while combining them to form sample-level features\n",
    " - LSTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
